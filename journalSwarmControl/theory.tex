%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Theory}
\label{sec:theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Theory:
%% Models (of each robot, of the global input)
%% Impossibility result
%% Controlling Mean proof
%% Controlling Variance proof (CLF)
%% A Hybrid controller using hysteresis
Consider holonomic robots that move in the 2D plane. We want to control position and velocity of the robots. 
First, assume a noiseless system containing one robot with mass $m$.
 Our inputs are global forces $[u_x,u_y]$. We define our state vector $\mathbf{x}(t)$ as the $x$ position, $x$ velocity, $y$ position and $y$ velocity.
The state-space representation in standard form is: 
\begin{align}\label{eq:stdform}
\dot{\mathbf{x}}(t)  &=  A \mathbf{x}(t) + B \mathbf{u}(t)
\end{align}

and our state space representation as:
\begin{equation}
\begin{bmatrix}
\dot{x}\\ 
\ddot{x}\\
\dot{y}\\
\ddot{y}
\end{bmatrix} = \begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 0
\end{bmatrix}  \begin{bmatrix}
x\\
\dot{x}\\
y\\
\dot{y}
\end{bmatrix} + \begin{bmatrix}
0 & 0 \\
\frac{1}{m} & 0 \\
0 & 0 \\
0 & \frac{1}{m}
\end{bmatrix}  [u_x,u_y]
\end{equation}

We want to find the number of states that we can control, which is given by the rank of the \emph{controllability matrix}
\begin{equation}
\mathcal{C} = [ B, AB, A^2B, ... , A^{n-1}B ].
\end{equation}

\begin{equation}
\textrm{Here }
\mathcal{C}=\left[
\begin{matrix} 
0 & 0\\
\frac{1}{m} & 0 \\
0 & 0 \\
0 & \frac{1}{m}
\end{matrix}
\,\middle\vert\,
\begin{matrix} 
\frac{1}{m}& 0\\
0 & 0\\
0 & \frac{1}{m}\\
0 & 0
\end{matrix}
\,\middle\vert\,
\begin{matrix} 
0 & 0\\
0 & 0 \\
0 & 0 \\
0 & 0
\end{matrix}
\,\middle\vert\,
\begin{matrix} 
0 & 0\\
0 & 0\\
0 & 0\\
0 & 0
\end{matrix}
 \right],
\end{equation}
and thus all four states are controllable. This Section starts by proving independent position control of many robots is not possible, but the mean position can be controlled. We then provide conditions under which the variance of many robots is also controllable.

\subsection{Independent control of many robots is impossible}
A single robot is fully controllable. For holonomic robots, movement in the $x$ and $y$ coordinates are independent, so for notational convenience without loss of generality we will focus only on movement in the $x$ axis. Given $n$ robots to be  controlled in the $x$ axis, there are $2n$ states: $n$ positions and $n$ velocities.
%\begin{equation}\left[ x_{1,1},x_{2,1},\ldots, x_{2n-1},x_{2n}\right]^\intercal = \left[ p_{x,1},v_{x,1},\ldots,p_{x,n},v_{x,n}\right]^\intercal. \nonumber\end{equation}
%\begin{align}
%\dot{p}_{x1} &= v_{x1}\\\nonumber
%\dot{v}_{x1} &= a_{x1}\\\nonumber
%\dot{p}_{x2} &= v_{x2}\\\nonumber
%\dot{v}_{x2} &= a_{x2}\\\nonumber
%&\vdots\\\nonumber
%\dot{p}_{xn} &= v_{xn}\\\nonumber
%\dot{v}_{xn} &= a_{xn}\nonumber
%\end{align}
Our state-space representation is:
\begin{equation}
\begin{bmatrix}
\dot{x}_{1}\\ 
\ddot{x}_{1}\\
\vdots\\
\dot{x}_{n}\\
\ddot{x}_{n}

\end{bmatrix} = \begin{bmatrix}
0 & 1 & \ldots & 0 & 0 \\
0 & 0 & \ldots& 0 & 0 \\
\vdots &  \vdots & \ddots & \vdots & \vdots \\
0 & 0  & \ldots & 0 & 1 \\
0 & 0 & \ldots& 0 & 0 
\end{bmatrix}  \begin{bmatrix}
x_{1}\\
\dot{x}_{1}\\
\vdots \\
x_{n}\\
\dot{x}_{n}
\end{bmatrix} + \begin{bmatrix}
0\\
1\\
\vdots\\
0\\
1
\end{bmatrix} u_x
\end{equation}
 However, just as with one robot, we can only control two states because $\mathcal{C}$ has rank two:
\begin{equation}
\mathcal{C}=\left[ \begin{matrix} 
0\\
1\\
\vdots\\
0\\
1
\end{matrix}
\,\middle\vert\,
  \begin{matrix} 
1\\
0\\
\vdots\\
1\\
0
\end{matrix}
\,\middle\vert\,
\begin{matrix} 
0\\
0\\
\vdots\\
0\\
0
\end{matrix}
\,\middle\vert\,
\begin{matrix} 
0\\
0\\
\vdots\\
0\\
0
\end{matrix}\,\middle\vert\,, 
\ldots \right]
\end{equation}  
\subsection{Controlling mean position of many robots}\label{sec:controlMeanPosition}
This means \emph{any} number of robots controlled by a global command have just two controllable states in each axis. We cannot arbitrarily control the position and velocity of two or more robots, but have options on which states to control.  One option is to control the position and velocity of the $j^{th}$ robot. To find a potentially more useful option, we create the following reduced order system that represents the average $x$ position and velocity of the $n$ robots:
\begin{align}
\begin{bmatrix}\nonumber
\dot{\bar{x}} \\
\ddot{\bar{x}}
\end{bmatrix} &= \frac{1}{n} \begin{bmatrix}
0& 1& \ldots &0& 1 \\
0& 0& \ldots &0& 0
\end{bmatrix}
\begin{bmatrix}
x_{1}\\
\dot{x}_{1}\\
\vdots\\
x_{n}\\
\dot{x}_{n}
\end{bmatrix} 
+ \frac{1}{n}\begin{bmatrix}
0& 0&  \ldots &0& 0 \\
0& 1&  \ldots &0& 1
\end{bmatrix}\begin{bmatrix} 
0\\
1\\
\vdots\\
0\\
1
\end{bmatrix} u_x
\end{align}
Thus:
\begin{equation}
\begin{bmatrix}
\dot{\bar{x}} \\
\ddot{\bar{x}}
\end{bmatrix} = \begin{bmatrix}
0& 1 \\
0& 0
\end{bmatrix}
\begin{bmatrix}
\bar{x}\\
\dot{\bar{x}}
\end{bmatrix} + \begin{bmatrix} 
0\\
1
\end{bmatrix} u_x
\end{equation}

We again analyze $\mathcal{C}$:
\begin{equation}
\mathcal{C}=\left[ \begin{matrix} 
0\\
1
\end{matrix}
\,\middle\vert\,
 \begin{matrix} 
1\\
0
\end{matrix}
 \right]
\end{equation}
This matrix has rank two, and thus the average position and average velocity are controllable.


Due to symmetry of the control input, only the mean position and mean velocity are controllable. However, there are several techniques for breaking symmetry, for example by using obstacles as in \cite{Becker2013b}, or by allowing independent noise sources as in \cite{beckerIJRR2014}.

We control mean position with a PD controller that uses the mean position and mean velocity. Our control input is the global force applied to each robot:
\begin{align}
u_x &= K_{p}(x_{goal} - \bar{x}) + K_{d}(0-\bar{v}_x) \nonumber\\
u_y &= K_{p}(y_{goal}  - \bar{y}) + K_{d}(0-\bar{v}_y)  \label{eq:PDcontrolPosition}
\end{align}
here $K_{p}$ is the proportional gain, and $K_{d}$ is the derivative gain. 


\subsection{Controlling the variance of many robots}\label{sec:VarianceControl}

The variance, $\sigma_x^2,\sigma_y^2$, of $n$ robots' position is computed as:
\begin{align}\label{eq:meanVar}
 \overline{x}(\mathbf{x}) = \frac{1}{n} \sum_{i=1}^n x_{i}, \qquad  %\nonumber \\ 
\sigma_x^2(\mathbf{x}) &= \frac{1}{n} \sum_{i=1}^n (x_{i} - \overline{x})^2,  \nonumber \\ 
 \overline{y}(\mathbf{x}) = \frac{1}{n} \sum_{i=1}^n y_{i}, \qquad  %\nonumber \\ 
\sigma_y^2(\mathbf{x}) &= \frac{1}{n} \sum_{i=1}^n (y_{i} - \overline{y})^2.  
%NOT 1/(N-1) because we are measuring the actual Variance, not the variance of samples drawn from a distribution
\end{align}

Controlling the variance requires being able to increase and decrease the variance.  We will list a sufficient condition for each. 
Microscale systems are affected by unmodelled dynamics. 
These unmodelled dynamics are dominated by Brownian noise, described by~\cite{einstein1956investigations}. 
To model this~\eqref{eq:stdform} must be modified as follows:
\begin{align}
\dot{\mathbf{x}}(t)  &=  A \mathbf{x}(t) + B \mathbf{u}(t) + W \bm{\varepsilon}(t)
\end{align}
where $W\bm{\varepsilon}(t)$ is a random perturbation produced by Brownian noise with magnitude $W$. Given a large obstacle-free workspace, a \emph{Brownian noise} process increases the variance linearly with time.
\begin{equation}\dot{\sigma}_x^2(\mathbf{x}(t), \mathbf{u}(t) \Leftarrow 0)  = W \bm{\varepsilon} \end{equation}
 If faster dispersion is needed, the swarm can be pushed through obstacles such as a diffraction grating or Pachinko board~\cite{Becker2013b}. 

%After some time, Gaussian distribution shapes the outline of the robots because of the Brownian noise feature:\\
%\begin{equation}
%P(x) = \frac{1}{\sigma \sqrt{2\pi } }e^{ -  \frac{\left( x - \mu  \right)^2 } {2\sigma ^2 }}
%\end{equation}
If robots with radius $r$ are in a bounded environment with sides of length $[\ell_x, \ell_y]$, the unforced variance asymptotically grows to the variance of a uniform distribution,
\begin{align}
[\sigma_x^2,\sigma_y^2] = \frac{1}{12}[ (\ell_x - 2 r)^2,(\ell_y - 2 r)^2].\label{eq:VarianceUniformDistribution}
\end{align}

 A flat obstacle can be used to decrease variance. Pushing a group of dispersed robots against a flat obstacle will decrease their variance until the minimum-variance (maximum density) packing  is reached. For large $n$, ~\cite{graham1990penny} showed that the minimum-variance packing  for $n$ circles with radius $r$ is 
 \begin{align} \label{eq:optimalvar}
 \sigma^2_{optimal}(n,r) \approx   \frac{\sqrt{3}}{\pi} n r^2\approx 0.55 n r^2.
 \end{align} 
% Sloan minimized second moment U = 1/d^2 \sum_{i=1}^{n} || P_i - P ||^2 = (\sqrt{3} n^2)/(4 \pi), where d = 2r.
% Therefore the variance is d^2 (\sqrt{3} n^2)/(4 \pi), or 4^r^2 (\sqrt{3} n^2)/(4 \pi) = r^2 (\sqrt{3} n^2)/(\pi)If we only need to reduce variance in a single axis, the variance can be reduced to zero, given sufficient space.

We will prove the origin is globally asymptotically stabilizable by using a control-Lyapunov function, as in \citet{Lyapunov1992}.  A suitable Lyapunov function is the squared variance error:
\begin{align}
\label{eq:LyapunovVariance}
V(t,\bf{x})  &= \frac{1}{2} (\sigma^2(\mathbf{x}) - \sigma^2_{goal})^2\nonumber\\
\dot{V}(t,\bf{x}) &= (\sigma^2(\mathbf{x})-\sigma^2_{goal})\dot{\sigma}^2(\mathbf{x})
\end{align}
We note here that $V(t,\mathbf{x})$ is positive definite and radially unbounded, and $V(t,\mathbf{x}) \equiv 0$ only at $\sigma^2(\mathbf{x}) = \sigma^2_{goal}$.
To make $\dot{V}(t,\mathbf{x})$ negative semi-definite, we choose
\begin{align}\label{eq:controlVariance}
u(t) &=   \begin{cases}
	 \mbox{move to wall} &\mbox{if } \sigma^2(\mathbf{x})>\sigma^2_{goal} \\ 
	 \mbox{move from wall} & \mbox{if } \sigma^2(\mathbf{x}) \le \sigma^2_{goal}.
\end{cases} 
\end{align}
 For such a $u(t)$,
 \begin{align}
\dot{\sigma}^2(\mathbf{x}) &=   \begin{cases}
	 \mbox{negative} &\mbox{if } \sigma^2(\mathbf{x})> \max(\sigma^2_{goal}, \sigma^2_{optimal}(n,r))  \\ 
	 W \epsilon & \mbox{if } \sigma^2(\mathbf{x}) \le \sigma^2_{goal},
\end{cases} 
\end{align} and thus
$\dot{V}(t,{\bf x})$ is negative definite and the variance is globally asymptotically stabilizable.% \hfill$\blacksquare$ 



A  controller to regulate the variance to $\sigma^2_{ref}$ is:
\begin{align}
u_x &= K_{p}(x_{goal}(\sigma^2_{ref}) - \bar{x}) - K_{d}\bar{v}_x + K_{i}(\sigma^2_{ref}-\sigma^2_{x}) \nonumber\\
u_y &= K_{p}(y_{goal}(\sigma^2_{ref})  - \bar{y}) - K_{d}\bar{v}_y + K_{i}(\sigma^2_{ref}-\sigma^2_{y}).  \label{eq:PDcontrolVariance}
\end{align}
In a slight abuse of notation we call the gain scaling the variance error $K_i$ because the variance, if unregulated, integrates over time.
Eq.~\eqref{eq:PDcontrolVariance} assumes the nearest wall is to the left of the robot at $x=0$, and chooses a reference goal position that in steady-state would have the correct variance according to \eqref{eq:VarianceUniformDistribution}:
\begin{align}
x_{goal}(\sigma^2_{ref}) = r + \sqrt{3\sigma^2_{ref}}
\end{align}
 If another wall is closer, the signs of $[K_p,K_i]$ are inverted, and the location $x_{goal}$ is translated.  


\subsection{Controlling both mean and variance of many robots}

The mean and variance of the swarm cannot be controlled simultaneously, however if the dispersion due to Brownian motion is less than the maximum controlled speed, we can adopt the hybrid, hysteresis-based controller shown in Alg.~\ref{alg:MeanVarianceControl} to regulate the mean and variance.  Such a controller normally controls the mean position, but switches to minimizing variance if the variance exceeds some $\sigma_{max}^2$. 
 Variance is reduced until less than $\sigma_{min}^2$, then control again regulates the mean position. 
 This technique satisfies control objectives that evolve at different rates as in~\cite{kloetzer2007temporal}, and the hysteresis avoids rapid switching between control modes. The process is illustrated in Fig.~\ref{fig:hysteresis}. 


\begin{algorithm}
\caption{Hybrid mean and variance control}\label{alg:MeanVarianceControl}
\begin{algorithmic}[1]
\Require Knowledge of swarm mean $[\bar{x},\bar{y}]$, variance $[\sigma_x^2, \sigma_y^2]$, the locations of the rectangular boundary $\{x_{min}, x_{max}, y_{min}, y_{max}\}$, and the target mean position $[x_{target},y_{target}]$.%TODO: use  \AND, \OR, \XOR, \NOT, \TO, \TRUE, \FALSE \gets
\State $flag_x \gets \FALSE$,  $flag_y \gets \FALSE$ 
\State $x_{goal} \gets  x_{target}$, $y_{goal} \gets y_{target}$
\Loop
%\State  Compute $\sigma_x^2, \sigma_y^2$

\If {$\sigma_x^2 > \sigma_{max}^2$}
\State $x_{goal}  \gets x_{min}$
\State $flag_x  \gets \TRUE$
\Else {\bf~if} {$flag_x$ \textbf{and} $\sigma_x^2 < \sigma_{min}^2$}
\State $x_{goal}  \gets  x_{target}$
\State $flag_x  \gets  \FALSE$
\EndIf

\If{$\sigma_y^2 > \sigma_{max}^2$}
\State $y_{goal}  \gets y_{min}$
\State $flag_y  \gets \TRUE$
\Else {\bf~if} {$flag_y$ \textbf{and} $\sigma_y^2 < \sigma_{min}^2$}
\State $y_{goal}  \gets  y_{target}$
\State $flag_y  \gets \FALSE$
\EndIf
\State Apply \eqref{eq:PDcontrolPosition} to move toward $[x_{goal}, y_{goal}]$
\EndLoop
\end{algorithmic}
\end{algorithm}


\begin{figure}
\centering
\begin{overpic}[width = 0.5\columnwidth]{hysteresis.png}
\put(33,21){$\sigma^2(\mathbf{x}) < \sigma^2_{min}$ }
\put(33,5){$\sigma^2(\mathbf{x}) > \sigma^2_{max}$}\end{overpic}
\begin{overpic}[width = 0.45\columnwidth]{VarianceMinMaxBand2v2.pdf}\end{overpic}
\vspace{-0.5em}
\caption{\label{fig:hysteresis} (Left) Two states to control mean and variance of a robot swarm. 
(Right) Switching conditions for variance control are set as a function of $n$, and designed to be larger than the optimal packing density. The plot uses robot radius $r=1/10$.
%\vspace{-2em}
}
\end{figure}

%\begin{figure}
%\centering
%\begin{overpic}[width = 0.5\columnwidth]{VarianceMinMaxBand2v2.pdf}\end{overpic}
%\vspace{-1em}
%\caption{\label{fig:VarianceMinMaxBand} The switching conditions for variance control are set as a function of $n$, and designed to be larger than the optimal packing density. The above plot uses robot radius $r=1/10$.
%}\vspace{-1em}
%\end{figure}


A key challenge is to select proper values for $\sigma_{min}^2$ and $\sigma_{max}^2$.  The optimal packing variance was given in \eqref{eq:optimalvar}.
The random packings generated by pushing our robots into corners are suboptimal, so we choose the conservative values shown in Fig.~\ref{fig:hysteresis}:
\begin{align}
 \sigma^2_{min} &= 2.5r+ \sigma^2_{optimal}(n,r) \nonumber\\
  \sigma^2_{max} &= 15r+ \sigma^2_{optimal}(n,r).
  \end{align}
%\sigma \approx 0.371258 n r,   \sigma_{min} = n*r*1/2, \sigma_{min} = n*r*3/2, 
%  this result was verified in http://www-math.mit.edu/~tchow/penny.pdf

%$\sigma^2_{optimal}(n,r)$ for $n$ circles with radius $r$ is $\approx 
 %    \frac{\sqrt{3}}{\pi} (n r)^2\approx 0.55(n r)^2 $. 
% Sloan minimized second moment U = 1/d^2 \sum_{i=1}^{n} || P_i - P ||^2 = (\sqrt{3} n^2)/(4 \pi), where d = 2r.
% Therefore the variance is d^2 (\sqrt{3} n^2)/(4 \pi), or 4^r^2 (\sqrt{3} n^2)/(4 \pi) = r^2 (\sqrt{3} n^2)/(\pi)If we only need to reduce variance in a single axis, the variance can be reduced to zero, given sufficient space.





%what images should I show here?
%hysteresis control law, \cite{sadra2014}










