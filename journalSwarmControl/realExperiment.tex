
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Object manipulation with hardware robots}\label{sec:realExperiment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  
\subsection{Environmental setup}
Our experiments use centimeter-scale hardware systems called \emph{kilobots}.  While those are far larger than the micro scale devices we model, using kilobots allows us to emulate a variety of dynamics, while enabling a high degree of control over robot function, the environment, and data collection. The kilobot \cite{Rubenstein2012,rubenstein2014programmable} is a low-cost robot designed for testing collective algorithms with large numbers of robots. It is available commercially or as an open source platform~\cite{K-Team2015}.  Each robot is approximately 3 cm in diameter, 3 cm tall, and uses two vibration motors to move on a flat surface at speeds up to 1 cm/s.  Each robot has one ambient light sensor that is used to implement \emph{phototaxis},  moving towards a light source. 
In these experiments as shown in Fig.~\ref{fig:setup}, we used $n$=100 kilobots, a 1.5 m$\times$1.2 m whiteboard as the workspace, and lights: four 50W LED floodlights  at the corners and four 30W LED floodlights on the sides of a 6 m square centered on the workspace and 1.5 m above the table. The lights were controlled using an Arduino Uno board connected to an 8 relay shield board.  Above the table, an overhead machine vision system tracks the position of the swarm. Laser-cut patterns for the neon green fiducial markers and {\sc Matlab} tracking code are available at our github repository~\cite{Shahrokhi2015GitHubShapeControl}.
\begin{figure*}
\begin{center}
	%\includegraphics[width=0.5\columnwidth]{SetUp.pdf}
	\begin{overpic}[width=0.49\columnwidth]{SetUp.pdf}\put(1,75){a)}\end{overpic}
	\begin{overpic}[width=0.35\columnwidth]{MainExpFig.pdf}\put(1,92){b)}\end{overpic}
\end{center}

\caption{\label{fig:setup}
Hardware platform:  table with 1.5$\times$1.2 m workspace, surrounded by eight remotely triggered 30W LED floodlights, with an overhead machine vision system (Left). A swarm of robots, all controlled by a uniform force field, can be effectively controlled by a hybrid controller that knows only the first and second moments of the robot distribution.  Here is a swarm of hardware robots (kilobots) that pushes a green hexagon toward the goal (Right). See video attachment~\cite{ShivaVideo2015}
}
\end{figure*}
%\subsection{Mean Control With Real Robots}

\begin{figure*}
\begin{center}
	\begin{overpic}[width=0.6\columnwidth]{Mean_Control_experiment.eps}\end{overpic}
	\begin{overpic}[width=0.35\columnwidth]{XYMeanControl.eps}\end{overpic}
\end{center}
\caption{\label{fig:realMean}
Mean Control plot with kilobots.
}
\end{figure*}

%\begin{figure}
%\begin{center}
%	\includegraphics[width=\columnwidth]{XYMeanControl.eps}
%\end{center}
%\caption{\label{fig:meanRobotFig}
%Mean Control experiment with kilobots.
%}
%\end{figure}

\subsection{Automated object manipulation (hardware experiment)}
\paragraph{Heuristics to handle outliers and improve performance}

The variance controller in Alg.~\ref{alg:MeanVarianceControl} is a greedy algorithm that is susceptible to outliers. The controller in \cite{Shahrokhi2015} failed in $14\%$ trials, often because workspace obstacles made some robots unable to reach the object. This failure rate increases if  object weight increases or ground-robot friction increases. The mean and covariance calculations \eqref{eq:meanVar} included all robots in the workspace. Robots that cannot reach the object due to obstacles skew these calculations. The state machine in Fig.\ \ref{fig:Region}.a solves this problem by creating two states for the maze: either main or transfer. Each state has a set of regions representing a discretized visibility polygon. Whenever the object crosses a region boundary the state toggles. The main regions are generated by extending obstacles until they meet another obstacle shown in Fig.~\ref{fig:Region}.b. The transfer regions are perpendicular to obstacle boundaries, and act as a buffer between two main regions shown in Fig.~\ref{fig:Region}.c.
This filtering increases experimental success because the mean calculation only includes nearby robots that can directly interact with the object. In the example, we want the robots to push the object to the right. Without filtering the robots, the orange star is the mean and the algorithm would instruct the robots to push the object southeast. The filtered mean is at the yellow star and the algorithm instructs the robots to push the object directly east. 
%When the object leaves main region 1 the maze state switches to transfer. 
%The object is in transfer region 0, so only robots in transfer region 0 are included in the mean and covariance calculations.  
This heuristic improves performance by $50\%$ or less regarding the object heaviness.
\begin{figure*}
\begin{center}
	\begin{overpic}[width=0.45\columnwidth]{mainRegions.pdf}\end{overpic}
	\begin{overpic}[width=0.45\columnwidth]{transferRegions.pdf}\end{overpic}
	\begin{overpic}[width=0.45\columnwidth]{stateMachine.pdf}\end{overpic}
\end{center}
\caption{\label{fig:Region} The state machine and regions.
}
\end{figure*}

\paragraph{Potential fields for swarm management}

Unfortunately, when the swarm is in front of the object, control law \eqref{eq:PDcontrolPosition} pushes the object backwards.  To fix this, we implement a potential field approach \cite{spong2008robot} that attracts the swarm to the intermediate goal, but repulses the swarm from in front of the object.
The repulsive potential field is centered at object's COM and is active for a radius $\rho_0$, but is implemented only when the swarm mean is within $\theta$ of the desired direction of motion as it is shown in Fig.~\ref{fig:potentialField}.
\begin{equation}
F_{att} = -\zeta \Delta \rho / \rho 
\end{equation}

\[ F_{rep} =  \left\{
\begin{array}{ll}
      \eta( 1/\rho- 1/\rho_0) \frac{1}{\rho^2} \Delta \rho & \rho\leq \rho_0 ~\&~ \theta > \pi/2\\
      0 & otherwise \\
\end{array} 
\right. \]

In simulations, $\theta =  \pi/2$,  $\eta  = 75$, $\zeta = 2$ and $\rho_0 = 3$ . Because the kilobot hardware experiments have a slower time constant, they use $\theta =  \pi/2$,  $\eta  = 50$, $\zeta = 1$ and $\rho_0 = 7.5$. 



\begin{figure}
\centering
\begin{overpic}[width=1\columnwidth]{PotentialField.pdf}\end{overpic}
%\todo{I like the 'target' symbol, but it is not self-documenting.  We need a legend explaining the min and max variance ellipses, the goal region, the variance, the mean, the object COM, and the target mean position.  I think these are easiest to make in powerpoint.
%Please use the same color and line style for the variance min and max as you use in Figure 4.
%}
%{blockpushingImageWithMeanAndVarianceOverlay.png}
\caption{\label{fig:potentialField} The attractive filed source is centered on (left). Repulsive field source is centered at object's COM(middle). We use a combined forces to use this method to avoid pushing the object backwards(right).}
\end{figure}